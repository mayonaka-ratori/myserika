"""
expense_manager.py
MoneyForward ME CSV ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ»çµŒè²»ç…§åˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã€‚
ExpenseManager ã‚¯ãƒ©ã‚¹ã§ CSV ã®å–ã‚Šè¾¼ã¿ã¨ expenses ãƒ†ãƒ¼ãƒ–ãƒ«ã¨ã®ç…§åˆã‚’æ‹…å½“ã™ã‚‹ã€‚
"""

import asyncio
import csv
import json
import logging
import re
from datetime import datetime, timedelta

logger = logging.getLogger(__name__)

# MF CSV column name mapping (Japanese header â†’ internal key)
_MF_COLUMN_MAP = {
    "è¨ˆç®—å¯¾è±¡":     "is_calculation_target",
    "æ—¥ä»˜":         "date",
    "å†…å®¹":         "content",
    "é‡‘é¡ï¼ˆå††ï¼‰":   "amount",
    "ä¿æœ‰é‡‘èæ©Ÿé–¢": "source_account",
    "å¤§é …ç›®":       "large_category",
    "ä¸­é …ç›®":       "medium_category",
    "ãƒ¡ãƒ¢":         "memo",
    "æŒ¯æ›¿":         "is_transfer",
    "ID":           "mf_id",
}

# Keyword â†’ tax category mapping for Japanese freelancer accounts
CATEGORY_KEYWORDS: dict[str, list[str]] = {
    "é€šä¿¡è²»":     ["æºå¸¯", "Wi-Fi", "ãƒ—ãƒ­ãƒã‚¤ãƒ€", "ã‚µãƒ¼ãƒãƒ¼", "ãƒ‰ãƒ¡ã‚¤ãƒ³", "SIM"],
    "æ—…è²»äº¤é€šè²»": ["é›»è»Š", "ãƒã‚¹", "ã‚¿ã‚¯ã‚·ãƒ¼", "æ–°å¹¹ç·š", "é£›è¡Œæ©Ÿ", "ETC", "Suica", "PASMO"],
    "æ¶ˆè€—å“è²»":   ["æ–‡æˆ¿å…·", "ã‚¤ãƒ³ã‚¯", "USB", "ã‚±ãƒ¼ãƒ–ãƒ«", "ãƒã‚¦ã‚¹", "ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰"],
    "æ¥å¾…äº¤éš›è²»": ["ä¼šé£Ÿ", "ãŠä¸­å…ƒ", "ãŠæ­³æš®", "æ…¶å¼”", "è´ˆç­”"],
    "ä¼šè­°è²»":     ["ã‚«ãƒ•ã‚§", "ã‚¹ã‚¿ãƒ", "ãƒ‰ãƒˆãƒ¼ãƒ«", "æ‰“ã¡åˆã‚ã›"],
    "åœ°ä»£å®¶è³ƒ":   ["äº‹å‹™æ‰€", "ã‚³ãƒ¯ãƒ¼ã‚­ãƒ³ã‚°", "ãƒ¬ãƒ³ã‚¿ãƒ«ã‚ªãƒ•ã‚£ã‚¹"],
    "æ°´é“å…‰ç†±è²»": ["é›»æ°—", "ã‚¬ã‚¹", "æ°´é“", "æ±äº¬é›»åŠ›", "æ±äº¬ã‚¬ã‚¹"],
    "åºƒå‘Šå®£ä¼è²»": ["Googleåºƒå‘Š", "SNSåºƒå‘Š", "ååˆº", "ãƒãƒ©ã‚·"],
    "å¤–æ³¨è²»":     ["ãƒ‡ã‚¶ã‚¤ãƒ³ä¾é ¼", "é–‹ç™ºä¾é ¼", "ç¿»è¨³", "Fiverr", "Lancers"],
    "æ–°èå›³æ›¸è²»": ["æ›¸ç±", "Kindle", "æŠ€è¡“æ›¸", "ã‚µãƒ–ã‚¹ã‚¯"],
    "ç ”ä¿®è²»":     ["ã‚»ãƒŸãƒŠãƒ¼", "å‹‰å¼·ä¼š", "Udemy", "ã‚ªãƒ³ãƒ©ã‚¤ãƒ³è¬›åº§"],
    "é›‘è²»":       [],
}

# CSV ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰å€™è£œï¼ˆBOM ä»˜ã UTF-8 ã‚’æœ€åˆã«è©¦ã™ï¼‰
_ENCODINGS = ["utf-8-sig", "shift-jis", "cp932"]


def _safe_int(v: object, default: int = 0) -> int:
    """Convert a value to int, tolerating comma separators, yen signs, and decimals.
    Returns default on any conversion failure."""
    try:
        return int(str(v).replace(",", "").replace("Â¥", "").replace("ï¿¥", "").split(".")[0])
    except (ValueError, TypeError):
        return default


def _parse_amount(s: str) -> int:
    """Convert a MoneyForward amount string like "1,234" / "-1,234" / "1,234.00" to int.
    Accepts decimal notation by truncating (not rounding) the fractional part."""
    s = s.strip().replace(",", "")
    if not s:
        return 0
    return int(float(s))


def _parse_flag(s: str) -> int:
    """"1" / "0" / "â—‹" / "" â†’ intï¼ˆ0 or 1ï¼‰ã«å¤‰æ›ã™ã‚‹ã€‚
    / Convert flag string to int."""
    s = s.strip()
    if s in ("1", "â—‹", "true", "True", "TRUE"):
        return 1
    return 0


def _partial_match_score(a: str, b: str) -> bool:
    """ç‰‡æ–¹ãŒã‚‚ã†ç‰‡æ–¹ã®éƒ¨åˆ†æ–‡å­—åˆ—ã‹ã‚’åˆ¤å®šï¼ˆç©ºç™½é™¤å»ãƒ»å°æ–‡å­—åŒ–å¾Œï¼‰ã€‚
    / Check if one string is a substring of the other after normalization."""
    a_norm = a.strip().lower().replace(" ", "").replace("ã€€", "")
    b_norm = b.strip().lower().replace(" ", "").replace("ã€€", "")
    if not a_norm or not b_norm:
        return False
    return a_norm in b_norm or b_norm in a_norm


class ExpenseManager:
    """
    MoneyForward ME CSV ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã¨çµŒè²»ç…§åˆã‚’æ‹…å½“ã™ã‚‹ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚¯ãƒ©ã‚¹ã€‚
    Manager class for importing MoneyForward ME CSV and matching expenses.
    """

    def __init__(self, db, gemini_client: dict):
        """
        db: Database ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ / Database instance
        gemini_client: gemini_client.init_client() ã®æˆ»ã‚Šå€¤è¾æ›¸
        / dict returned by gemini_client.init_client()
        """
        self._db = db
        self._gemini = gemini_client

    async def import_moneyforward_csv(self, file_path: str) -> dict:
        """Parse MoneyForward ME CSV and persist to DB.
        Returns {"imported": int, "skipped": int, "errors": list[str]}."""
        # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰é †è©¦è¡Œ
        content: str | None = None
        for enc in _ENCODINGS:
            try:
                with open(file_path, encoding=enc, newline="") as f:
                    content = f.read()
                logger.info(f"CSV ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰æ¤œå‡º: {enc}")
                break
            except (UnicodeDecodeError, LookupError):
                continue

        if content is None:
            raise ValueError("CSV ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã‚’åˆ¤å®šã§ãã¾ã›ã‚“ã§ã—ãŸã€‚/ Could not detect CSV encoding.")

        reader = csv.DictReader(content.splitlines())
        if reader.fieldnames is None:
            raise ValueError("CSV ãƒ˜ãƒƒãƒ€ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚/ CSV header not found.")

        new_count = 0
        skipped = 0
        errors: list[str] = []

        for row in reader:
            # ID ãŒç©ºã®è¡Œã¯ã‚¹ã‚­ãƒƒãƒ—
            raw_id = row.get("ID", "").strip()
            if not raw_id:
                skipped += 1
                continue

            # ã‚«ãƒ©ãƒ ãƒãƒƒãƒ”ãƒ³ã‚°
            mf_id = raw_id
            is_calculation_target = _parse_flag(row.get("è¨ˆç®—å¯¾è±¡", "1"))
            date_str = row.get("æ—¥ä»˜", "").strip()
            content_str = row.get("å†…å®¹", "").strip()
            amount_str = row.get("é‡‘é¡ï¼ˆå††ï¼‰", "0").strip()
            source_account = row.get("ä¿æœ‰é‡‘èæ©Ÿé–¢", "").strip()
            large_category = row.get("å¤§é …ç›®", "").strip()
            medium_category = row.get("ä¸­é …ç›®", "").strip()
            memo = row.get("ãƒ¡ãƒ¢", "").strip()
            is_transfer = _parse_flag(row.get("æŒ¯æ›¿", "0"))

            # æ—¥ä»˜ã‚’ YYYY-MM-DD ã«æ­£è¦åŒ–
            date_normalized = _normalize_date(date_str)
            if not date_normalized:
                msg = f"Date parse failed for ID={mf_id}: {date_str!r}"
                logger.warning(msg)
                errors.append(msg)
                skipped += 1
                continue

            try:
                amount = _parse_amount(amount_str)
            except ValueError:
                msg = f"Amount parse failed for ID={mf_id}: {amount_str!r}"
                logger.warning(msg)
                errors.append(msg)
                skipped += 1
                continue

            inserted = await self._db.save_mf_transaction(
                mf_id=mf_id,
                is_calculation_target=is_calculation_target,
                date=date_normalized,
                content=content_str,
                amount=amount,
                source_account=source_account,
                large_category=large_category,
                medium_category=medium_category,
                memo=memo,
                is_transfer=is_transfer,
            )
            if inserted:
                new_count += 1
            else:
                skipped += 1  # duplicate mf_id already in DB

        logger.info(
            f"MF CSV import done: {new_count} new, {skipped} skipped, {len(errors)} errors"
        )
        return {"imported": new_count, "skipped": skipped, "errors": errors}

    async def match_with_moneyforward(self) -> list[dict]:
        """Find MoneyForward candidates for unmatched expense records.

        Confidence levels:
          - "certain":   Â±1-day, exact amount, name similarity â†’ auto-matched silently.
          - "likely":    Â±2-day, exact amount, not "certain"   â†’ returned for user review.
          - "uncertain": amount-only match, outside Â±2-day     â†’ returned for manual review.

        Returns only "likely" and "uncertain" items; "certain" are resolved in DB automatically.
        """
        try:
            unmatched_expenses = await self._db.get_unmatched_expenses()
        except Exception as e:
            logger.error(f"Error fetching unmatched expenses: {e}")
            return []

        results = []

        for expense in unmatched_expenses:
            expense_date = expense.get("date", "")
            expense_amount = expense.get("amount", 0)
            expense_desc = expense.get("store_name", "")
            abs_amount = abs(expense_amount)

            # Step 1: Â±2-day, exact-amount, spending-only MF candidates
            candidates_2day = await self._get_mf_candidates_in_range(
                expense_date, abs_amount, days=2
            )

            found_mf_ids: set[str] = set()
            certain_matched = False
            likely_candidates: list[dict] = []

            for mf in candidates_2day:
                mf_id = mf.get("mf_id", "")
                found_mf_ids.add(mf_id)
                mf_content = mf.get("content", "")

                # Calendar-day delta to distinguish Â±1-day ("certain") from Â±2-day ("likely")
                try:
                    mf_dt = datetime.strptime(mf.get("date", "")[:10], "%Y-%m-%d")
                    exp_dt = datetime.strptime(expense_date[:10], "%Y-%m-%d")
                    day_delta = abs((mf_dt - exp_dt).days)
                except (ValueError, TypeError):
                    day_delta = 99

                # Name similarity: substring first, Gemini as fallback
                name_match = _partial_match_score(expense_desc, mf_content)
                if not name_match:
                    try:
                        name_match = await self._gemini_similarity_check(
                            expense_desc, mf_content
                        )
                    except Exception as e:
                        logger.warning(f"Gemini similarity check skipped: {e}")

                if day_delta <= 1 and name_match and not certain_matched:
                    # "certain" â†’ auto-match silently, do not add to results
                    try:
                        await self._db.match_expense_to_mf(expense["id"], mf_id)
                        certain_matched = True
                        logger.info(
                            f"Auto-matched expense {expense['id']} to MF {mf_id} (certain)"
                        )
                    except Exception as e:
                        logger.error(f"Auto-match DB write error: {e}")
                        # Fall back to manual review so the candidate is not silently lost
                        likely_candidates.append({"mf": mf, "confidence": "likely"})
                else:
                    likely_candidates.append({"mf": mf, "confidence": "likely"})

            if certain_matched:
                continue  # expense fully resolved â€” move to next

            # Step 2: Amount-only matches outside the Â±2-day window ("uncertain")
            uncertain_candidates: list[dict] = []
            for mf in await self._get_mf_candidates_amount_only(abs_amount, found_mf_ids):
                uncertain_candidates.append({"mf": mf, "confidence": "uncertain"})

            results.append({
                "expense": expense,
                "candidates": likely_candidates + uncertain_candidates,
            })

        return results

    async def _get_mf_candidates_in_range(
        self, date_str: str, amount: int, days: int = 2
    ) -> list[dict]:
        """Return MF spending transactions within Â±days of date with matching absolute amount.
        Delegates to Database.get_mf_candidates_by_range; returns [] on any error."""
        try:
            base_date = datetime.strptime(date_str[:10], "%Y-%m-%d")
        except (ValueError, TypeError):
            return []

        date_from = (base_date - timedelta(days=days)).strftime("%Y-%m-%d")
        date_to = (base_date + timedelta(days=days)).strftime("%Y-%m-%d")
        abs_amount = abs(amount)

        try:
            return await self._db.get_mf_candidates_by_range(date_from, date_to, abs_amount)
        except Exception as e:
            logger.error(f"MF candidate fetch error: {e}")
            return []

    async def _get_mf_candidates_amount_only(
        self, abs_amount: int, exclude_mf_ids: set[str] | None = None
    ) -> list[dict]:
        """Return MF spending transactions matching the absolute amount with no date constraint.
        Used for 'uncertain' confidence matches where only the amount aligns.
        Delegates to Database.get_mf_candidates_by_amount; returns [] on any error."""
        try:
            return await self._db.get_mf_candidates_by_amount(abs_amount, exclude_mf_ids)
        except Exception as e:
            logger.error(f"MF amount-only candidate fetch error: {e}")
            return []

    def rule_based_categorize(
        self, store_name: str, items_text: str = ""
    ) -> tuple[str, None] | None:
        """Match store name and items text against CATEGORY_KEYWORDS dictionary.
        Returns (category, None) on first keyword match, or None if no match found.
        subcategory is always None for rule-based matching."""
        haystack = f"{store_name} {items_text}".lower()
        for category, keywords in CATEGORY_KEYWORDS.items():
            for keyword in keywords:
                if keyword.lower() in haystack:
                    return (category, None)
        return None

    async def analyze_receipt_image(self, image_path: str) -> dict:
        """OCR a receipt image using Gemini vision and return structured data.

        Resizes images to max 1024px on the longest side before sending to Gemini
        to reduce token usage. Never raises â€” returns a partial/empty dict on failure.

        Returns:
            {
                "date": str | None,      # YYYY-MM-DD
                "store_name": str,       # fallback "ä¸æ˜"
                "items": list[dict],     # [{"name": str, "price": int, "quantity": int}]
                "subtotal": int | None,
                "tax": int | None,
                "total": int,            # fallback 0
                "payment_method": str,   # "cash" / "credit_card" / "electronic"
            }
        """
        _FALLBACK: dict = {
            "date": None,
            "store_name": "ä¸æ˜",
            "items": [],
            "subtotal": None,
            "tax": None,
            "total": 0,
            "payment_method": "cash",
        }

        try:
            from PIL import Image  # deferred â€” bot still starts if Pillow missing
        except ImportError:
            logger.error("Pillow is not installed; cannot OCR receipt images")
            return _FALLBACK

        client = self._gemini.get("client")
        model = self._gemini.get("model", "gemini-2.5-flash")
        if client is None:
            logger.error("Gemini client not initialized; cannot OCR receipt image")
            return _FALLBACK

        try:
            with Image.open(image_path) as _raw:
                # Resize so the longest side is at most 1024 px
                if max(_raw.width, _raw.height) > 1024:
                    _raw.thumbnail((1024, 1024), Image.LANCZOS)
                # Convert to RGB (handles RGBA PNGs, palette images, etc.)
                img = _raw.convert("RGB") if _raw.mode != "RGB" else _raw.copy()
        except Exception as e:
            logger.error(f"Failed to open/resize receipt image {image_path}: {e}")
            return _FALLBACK

        ocr_prompt = (
            "ã“ã®ãƒ¬ã‚·ãƒ¼ãƒˆç”»åƒã‹ã‚‰ä»¥ä¸‹ã®æƒ…å ±ã‚’JSONå½¢å¼ã§æŠ½å‡ºã—ã¦ãã ã•ã„ï¼š\n"
            "{\n"
            '  "date": "YYYY-MM-DDï¼ˆè³¼å…¥æ—¥ï¼‰",\n'
            '  "store_name": "åº—å",\n'
            '  "items": [{"name": "å“å", "price": å˜ä¾¡, "quantity": æ•°é‡}],\n'
            '  "subtotal": å°è¨ˆ,\n'
            '  "tax": æ¶ˆè²»ç¨é¡,\n'
            '  "total": åˆè¨ˆé‡‘é¡,\n'
            '  "payment_method": "æ”¯æ‰•æ–¹æ³•ï¼ˆè¨˜è¼‰ãŒã‚ã‚Œã° cash/credit_card/electronicã€ãªã‘ã‚Œã°nullï¼‰"\n'
            "}\n"
            "èª­ã¿å–ã‚Œãªã„é …ç›®ã¯nullã«ã—ã¦ãã ã•ã„ã€‚"
        )

        try:
            response = await asyncio.to_thread(
                client.models.generate_content, model=model, contents=[img, ocr_prompt]
            )
            raw_text = response.text or ""
        except Exception as e:
            logger.error(f"Gemini vision API error for {image_path}: {e}")
            return _FALLBACK

        # Parse JSON â€” strip markdown fences then regex-extract the object
        try:
            cleaned = re.sub(r"```(?:json)?\s*", "", raw_text).strip().rstrip("`").strip()
            m = re.search(r"\{.*\}", cleaned, re.DOTALL)
            if not m:
                raise ValueError("No JSON object found in Gemini response")
            parsed = json.loads(m.group())
        except Exception as e:
            logger.warning(f"Receipt OCR JSON parse failed ({e}); returning partial data")
            parsed = {}

        # Normalize and coerce each field
        valid_payment = {"cash", "credit_card", "electronic"}
        pm_raw = parsed.get("payment_method") or "cash"
        payment_method = pm_raw if pm_raw in valid_payment else "cash"

        items_raw = parsed.get("items")
        items: list[dict] = []
        if isinstance(items_raw, list):
            for it in items_raw:
                if isinstance(it, dict):
                    items.append({
                        "name":     str(it.get("name") or ""),
                        "price":    _safe_int(it.get("price"), 0),
                        "quantity": _safe_int(it.get("quantity"), 1),
                    })

        def _to_int_or_none(v: object) -> int | None:
            if v is None:
                return None
            try:
                return int(
                    str(v).replace(",", "").replace("Â¥", "").replace("ï¿¥", "").split(".")[0]
                )
            except (ValueError, TypeError):
                return None

        date_raw = parsed.get("date")
        date_ok = (
            date_raw if isinstance(date_raw, str) and re.match(r"\d{4}-\d{2}-\d{2}$", date_raw)
            else None
        )

        return {
            "date":           date_ok,
            "store_name":     str(parsed.get("store_name") or "ä¸æ˜"),
            "items":          items,
            "subtotal":       _to_int_or_none(parsed.get("subtotal")),
            "tax":            _to_int_or_none(parsed.get("tax")),
            "total":          _safe_int(parsed.get("total"), 0),
            "payment_method": payment_method,
        }

    async def auto_categorize(
        self, store_name: str, items: list[dict]
    ) -> tuple[str, str | None]:
        """Determine the tax category for an expense using a three-stage pipeline:
        1. Rule-based keyword match (instant, no API call)
        2. DB history: reuse category if same store_name was seen before
        3. Gemini LLM fallback (Japanese prompt for accuracy)
        Returns (category, subcategory) â€” always succeeds, falls back to ("é›‘è²»", None).
        """
        items_text = " ".join(item.get("name", "") for item in items if item.get("name"))

        # Stage 1: rule-based keyword match
        rule_result = self.rule_based_categorize(store_name, items_text)
        if rule_result is not None:
            return rule_result

        # Stage 2: DB history â€” same store_name used before
        try:
            past = await self._db.get_expenses(store_name=store_name.strip(), limit=1)
            if past:
                cat = past[0].get("category") or ""
                if cat:
                    sub = past[0].get("subcategory") or None
                    logger.debug(
                        f"auto_categorize: DB history match for '{store_name}' â†’ {cat}"
                    )
                    return (cat, sub)
        except Exception as e:
            logger.warning(f"auto_categorize: DB history lookup failed: {e}")

        # Stage 3: Gemini fallback
        client = self._gemini.get("client")
        model = self._gemini.get("model", "gemini-2.5-flash")
        if client is None:
            return ("é›‘è²»", None)

        category_list = "ã€".join(CATEGORY_KEYWORDS.keys())
        items_summary = items_text[:200] if items_text else "ï¼ˆå“ç›®ä¸æ˜ï¼‰"
        prompt = (
            f"ãƒ•ãƒªãƒ¼ãƒ©ãƒ³ã‚¹ã®é’è‰²ç”³å‘Šã«ãŠã„ã¦ã€"
            f"åº—åã€Œ{store_name}ã€ã§ã®è³¼å…¥å“ã€Œ{items_summary}ã€ã¯"
            f"ã©ã®å‹˜å®šç§‘ç›®ã«åˆ†é¡ã™ã¹ãã§ã™ã‹ï¼Ÿ\n"
            f"é¸æŠè‚¢: {category_list}\n"
            f'JSONå½¢å¼ã®ã¿ã§å›ç­”ã—ã¦ãã ã•ã„: {{"category": "...", "subcategory": "...ã¾ãŸã¯null"}}'
        )

        try:
            response = await asyncio.to_thread(
                client.models.generate_content, model=model, contents=prompt
            )
            raw = response.text or ""
            cleaned = re.sub(r"```(?:json)?\s*", "", raw).strip().rstrip("`").strip()
            m = re.search(r"\{.*\}", cleaned, re.DOTALL)
            if not m:
                raise ValueError("No JSON in Gemini categorize response")
            parsed = json.loads(m.group())
            cat = str(parsed.get("category") or "").strip()
            sub_raw = parsed.get("subcategory")
            sub = str(sub_raw).strip() if sub_raw and str(sub_raw).lower() != "null" else None
            if cat in CATEGORY_KEYWORDS:
                logger.debug(
                    f"auto_categorize: Gemini result for '{store_name}' â†’ {cat}"
                )
                return (cat, sub)
        except Exception as e:
            logger.warning(f"auto_categorize: Gemini fallback failed: {e}")

        return ("é›‘è²»", None)

    async def _gemini_similarity_check(self, content_a: str, content_b: str) -> bool:
        """Use Gemini to check if two store names / descriptions refer to the same transaction.
        Returns True if Gemini answers "yes", False otherwise or on any error."""
        if not content_a or not content_b:
            return False

        prompt = (
            "ä»¥ä¸‹ã®2ã¤ã®åº—åãƒ»å†…å®¹ãŒåŒä¸€å–å¼•ã‚’æŒ‡ã—ã¦ã„ã‚‹ã‹ yes/no ã®ã¿ã§ç­”ãˆã¦ãã ã•ã„ã€‚\n\n"
            f"A: {content_a}\n"
            f"B: {content_b}"
        )

        try:
            client = self._gemini.get("client")
            model = self._gemini.get("model", "gemini-2.5-flash")
            if client is None:
                return False
            response = await asyncio.to_thread(
                client.models.generate_content, model=model, contents=prompt
            )
            answer = response.text.strip().lower()
            return "yes" in answer
        except Exception as e:
            logger.warning(f"Gemini similarity check failed: {e}")
            return False


    async def generate_monthly_report(self, year: int, month: int) -> str:
        """Generate a formatted text report for the given year/month.

        Includes per-category breakdown (name, amount, count), grand total,
        payment method split (cash vs card), and MoneyForward match rate.
        Returns a plain text string suitable for Telegram or web display.
        """
        month_str = f"{year:04d}-{month:02d}"
        rows = await self._db.get_monthly_summary(year, month)

        # Fetch payment method breakdown and MF match rate via Database abstraction
        cash_total = card_total = other_total = 0
        try:
            report_data = await self._db.get_monthly_expense_report_data(month_str)
            for pmr in report_data["payment_rows"]:
                pm = (pmr["payment_method"] or "cash").lower()
                t = abs(pmr["total"] or 0)
                if pm == "cash":
                    cash_total = t
                elif pm in ("credit_card", "card"):
                    card_total = t
                else:
                    other_total += t
            total_count = report_data["total_count"]
            matched_count = report_data["matched_count"]
        except Exception as e:
            logger.warning(f"generate_monthly_report: DB query error: {e}")
            total_count = matched_count = 0

        # Build report text
        header = f"ğŸ“Š {year}å¹´{month:02d}æœˆ çµŒè²»ã‚µãƒãƒªãƒ¼"
        lines = [header, "â”€" * 28]

        grand_total = 0
        if rows:
            for r in rows:
                cat = r.get("category") or "æœªåˆ†é¡"
                amt = r.get("total_amount") or 0
                cnt = r.get("count") or 0
                grand_total += amt
                lines.append(f"  {cat:<12} Â¥{amt:>8,}  ({cnt}ä»¶)")
        else:
            lines.append("  ï¼ˆç™»éŒ²ã•ã‚ŒãŸçµŒè²»ã¯ã‚ã‚Šã¾ã›ã‚“ï¼‰")

        lines.append("â”€" * 28)
        lines.append(f"  åˆè¨ˆ             Â¥{grand_total:>8,}")
        lines.append("")

        # Payment method split
        lines.append("ğŸ’³ æ”¯æ‰•æ–¹æ³•å†…è¨³")
        lines.append(f"  ç¾é‡‘   Â¥{cash_total:>8,}")
        lines.append(f"  ã‚«ãƒ¼ãƒ‰ Â¥{card_total:>8,}")
        if other_total:
            lines.append(f"  ãã®ä»– Â¥{other_total:>8,}")

        # MF match rate
        if total_count > 0:
            rate = int(matched_count / total_count * 100)
            lines.append("")
            lines.append(f"ğŸ”— MF ç…§åˆç‡: {matched_count}/{total_count} ä»¶ ({rate}%)")

        return "\n".join(lines)

    async def generate_annual_report(self, year: int) -> dict:
        """Generate a structured annual report dict for the given year.

        Returns:
            {
                "year": int,
                "categories": [
                    {"name": str, "total": int, "count": int,
                     "monthly": {1: int, ..., 12: int}},
                    ...
                ],
                "grand_total": int,
                "monthly_totals": {1: int, ..., 12: int},
                "text": str,   # pre-formatted Telegram text
            }
        """
        # Annual totals per category
        annual_rows = await self._db.get_annual_summary(year)

        # Monthly breakdown per category: fetch each month separately
        monthly_by_cat: dict[str, dict[int, int]] = {}
        monthly_totals: dict[int, int] = {}

        for m in range(1, 13):
            month_rows = await self._db.get_monthly_summary(year, m)
            month_sum = 0
            for r in month_rows:
                cat = r.get("category") or "æœªåˆ†é¡"
                amt = r.get("total_amount") or 0
                monthly_by_cat.setdefault(cat, {})[m] = amt
                month_sum += amt
            monthly_totals[m] = month_sum

        # Build category list in annual-total order
        grand_total = 0
        categories = []
        for r in annual_rows:
            cat = r.get("category") or "æœªåˆ†é¡"
            total = r.get("total_amount") or 0
            count = r.get("count") or 0
            grand_total += total
            monthly = {m: monthly_by_cat.get(cat, {}).get(m, 0) for m in range(1, 13)}
            categories.append({
                "name": cat,
                "total": total,
                "count": count,
                "monthly": monthly,
            })

        # Build formatted text for Telegram display
        text_lines = [
            f"ğŸ“‹ {year}å¹´ å¹´é–“çµŒè²»ãƒ¬ãƒãƒ¼ãƒˆ",
            "â”€" * 30,
        ]
        if categories:
            for c in categories:
                text_lines.append(
                    f"  {c['name']:<12} Â¥{c['total']:>9,}  ({c['count']}ä»¶)"
                )
        else:
            text_lines.append("  ï¼ˆç™»éŒ²ã•ã‚ŒãŸçµŒè²»ã¯ã‚ã‚Šã¾ã›ã‚“ï¼‰")

        text_lines.append("â”€" * 30)
        text_lines.append(f"  å¹´é–“åˆè¨ˆ         Â¥{grand_total:>9,}")
        text_lines.append("")
        text_lines.append("æœˆåˆ¥åˆè¨ˆ")
        for m in range(1, 13):
            text_lines.append(f"  {m:02d}æœˆ  Â¥{monthly_totals[m]:>8,}")

        return {
            "year": year,
            "categories": categories,
            "grand_total": grand_total,
            "monthly_totals": monthly_totals,
            "text": "\n".join(text_lines),
        }

    async def export_annual_csv(self, year: int, output_path: str) -> str:
        """Export the annual expense report as a UTF-8 BOM CSV file.

        Columns: å‹˜å®šç§‘ç›®, é‡‘é¡, ä»¶æ•°
        UTF-8 with BOM so Excel on Japanese Windows opens it correctly.
        Creates parent directories as needed. Returns output_path.
        """
        import csv as _csv
        from pathlib import Path as _Path

        report = await self.generate_annual_report(year)
        out = _Path(output_path)
        out.parent.mkdir(parents=True, exist_ok=True)

        with open(out, "w", encoding="utf-8-sig", newline="") as f:
            writer = _csv.writer(f)
            writer.writerow(["å‹˜å®šç§‘ç›®", "é‡‘é¡", "ä»¶æ•°"])
            for c in report["categories"]:
                writer.writerow([c["name"], c["total"], c["count"]])
            # Footer row
            writer.writerow(["åˆè¨ˆ", report["grand_total"], sum(c["count"] for c in report["categories"])])

        logger.info(f"Annual CSV exported: {output_path} ({len(report['categories'])} categories)")
        return output_path


def _normalize_date(date_str: str) -> str:
    """å„ç¨®æ—¥ä»˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ YYYY-MM-DD ã«æ­£è¦åŒ–ã™ã‚‹ã€‚
    / Normalize various date formats to YYYY-MM-DD."""
    date_str = date_str.strip()
    if not date_str:
        return ""

    # YYYY/MM/DD
    for fmt in ("%Y/%m/%d", "%Y-%m-%d", "%Yå¹´%mæœˆ%dæ—¥"):
        try:
            return datetime.strptime(date_str, fmt).strftime("%Y-%m-%d")
        except ValueError:
            continue

    return ""
